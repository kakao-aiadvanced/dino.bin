{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-15T06:05:37.581944Z",
     "start_time": "2024-10-15T06:05:37.575545Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "import bs4\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T06:05:52.525328Z",
     "start_time": "2024-10-15T06:05:52.523449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]"
   ],
   "id": "b9d9348a0e5aa69a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T06:08:12.116053Z",
     "start_time": "2024-10-15T06:08:12.114172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader_multiple_pages = WebBaseLoader(urls)"
   ],
   "id": "b7cb93607725cac6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T06:10:55.762516Z",
     "start_time": "2024-10-15T06:10:53.547086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "documents = loader_multiple_pages.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "id": "18c0b0e87f7ae453",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T06:11:42.438528Z",
     "start_time": "2024-10-15T06:11:41.905972Z"
    }
   },
   "cell_type": "code",
   "source": "retriever.invoke(\"agent memory\")",
   "id": "31e67d9a9de6f783",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T06:16:34.444538Z",
     "start_time": "2024-10-15T06:16:34.400244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")"
   ],
   "id": "61cb0db065350e43",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T07:19:17.001741Z",
     "start_time": "2024-10-15T07:19:16.998798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Output in JSON format:\n",
    "relevance: true or false\n",
    "\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = (\n",
    "        prompt\n",
    "        | llm\n",
    "        | JsonOutputParser()\n",
    ")"
   ],
   "id": "ba2a078032f009bb",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T07:47:57.320128Z",
     "start_time": "2024-10-15T07:47:51.693337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"agent memory\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "answer_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "rag_chain = (\n",
    "        answer_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "hallucination_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "        You are given a context and an answer. Your task is to determine if the answer contains hallucination (false or invented information) or not. Respond \"True\" if the answer contains hallucination, and \"False\" if the answer is fully grounded in the provided context.\n",
    "        \n",
    "        Context: {context}\n",
    "        Answer: {answer}\n",
    "        \n",
    "        Output in JSON format:\n",
    "        hallucination: true or false\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\", \"answer\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "hallu_chain = (\n",
    "        hallucination_prompt\n",
    "        | llm\n",
    "        | JsonOutputParser()\n",
    ")\n",
    "\n",
    "if result[\"relevance\"]:\n",
    "    while True:\n",
    "        answer = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "        hallu_result = hallu_chain.invoke({\"context\": docs, \"answer\": answer})\n",
    "        if not hallu_result[\"hallucination\"]:\n",
    "            print(answer)\n",
    "            break\n",
    "else:\n",
    "    print(\"I don't know.\")"
   ],
   "id": "26c30e8ae28d5f71",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyobinsim/miniconda3/lib/python3.12/site-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent memory refers to a long-term memory module in LLM-powered autonomous agents that records experiences in natural language. It includes observations and events that can inform the agent's behavior through a retrieval model, which prioritizes recency, importance, and relevance. Additionally, a reflection mechanism synthesizes these memories into higher-level inferences, guiding future actions.\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8c0ebbe71a459d83"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
